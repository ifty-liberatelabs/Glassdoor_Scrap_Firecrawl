{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee744fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "glassdoor_urls = [\n",
    "    \"https://www.glassdoor.com/Reviews/Daffodil-International-University-Reviews-E1394524.htm\",\n",
    "    \"https://www.glassdoor.com/Reviews/International-Islamic-University-Chittagong-Reviews-E936727.htm\",\n",
    "    \"https://www.glassdoor.com/Reviews/East-Delta-University-Reviews-E2352449.htm\",\n",
    "    \"https://www.glassdoor.com/Reviews/North-South-University-Reviews-E465930.htm\",\n",
    "    \"https://www.glassdoor.com/Reviews/East-West-University-Reviews-E128305.htm\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7428c8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping the first page to get total reviews for: https://www.glassdoor.com/Reviews/Daffodil-International-University-Reviews-E1394524.htm\n",
      "‚úÖ Total reviews found: 102\n",
      "üßæ Total review tabs (pages): 11 \n",
      "\n",
      "Scraping the first page to get total reviews for: https://www.glassdoor.com/Reviews/International-Islamic-University-Chittagong-Reviews-E936727.htm\n",
      "‚úÖ Total reviews found: 25\n",
      "üßæ Total review tabs (pages): 3 \n",
      "\n",
      "Scraping the first page to get total reviews for: https://www.glassdoor.com/Reviews/East-Delta-University-Reviews-E2352449.htm\n",
      "‚úÖ Total reviews found: 11\n",
      "üßæ Total review tabs (pages): 2 \n",
      "\n",
      "Scraping the first page to get total reviews for: https://www.glassdoor.com/Reviews/North-South-University-Reviews-E465930.htm\n",
      "‚úÖ Total reviews found: 199\n",
      "üßæ Total review tabs (pages): 20 \n",
      "\n",
      "Scraping the first page to get total reviews for: https://www.glassdoor.com/Reviews/East-West-University-Reviews-E128305.htm\n",
      "‚úÖ Total reviews found: 45\n",
      "üßæ Total review tabs (pages): 5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from firecrawl import FirecrawlApp\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Load environment variables and Firecrawl API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"FIRECRAWL_API_KEY\")\n",
    "\n",
    "# Initialize Firecrawl client\n",
    "app = FirecrawlApp(api_key=api_key)\n",
    "\n",
    "# Dictionary to store total reviews & total pages for each link\n",
    "pages_info = {}\n",
    "\n",
    "# Loop over each Glassdoor URL, scrape the first page,\n",
    "# extract total reviews, and calculate total pages\n",
    "for g_url in glassdoor_urls:\n",
    "    print(f\"Scraping the first page to get total reviews for: {g_url}\")\n",
    "\n",
    "    # 1) Scrape the first page\n",
    "    result = app.crawl_url(\n",
    "        url=g_url,\n",
    "        params={\n",
    "            \"scrapeOptions\": {\n",
    "                \"formats\": [\"html\"]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Ensure we got valid data\n",
    "    if not result.get('data'):\n",
    "        print(\"‚ùå No data returned. Possible error or blocking for this URL.\\n\")\n",
    "        continue\n",
    "\n",
    "    html = result['data'][0]['html']\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 2) Find the <span> containing the total review count\n",
    "    span = soup.find(\"span\", class_=\"PaginationContainer_paginationCount__DdbVG\")\n",
    "    if not span:\n",
    "        print(\"‚ùå Could not find the pagination span for this URL.\\n\")\n",
    "        continue\n",
    "\n",
    "    text = span.get_text()  # Example: \"Viewing 1 - 10 of 120 Reviews\"\n",
    "    match = re.search(r\"Viewing\\s+\\d+\\s*-\\s*\\d+\\s+of\\s+([\\d,]+)\\s+Reviews\", text)\n",
    "\n",
    "    if match:\n",
    "        total_reviews = int(match.group(1).replace(\",\", \"\"))\n",
    "        total_tabs = math.ceil(total_reviews / 10)\n",
    "        pages_info[g_url] = (total_reviews, total_tabs)\n",
    "        print(\"‚úÖ Total reviews found:\", total_reviews)\n",
    "        print(\"üßæ Total review tabs (pages):\", total_tabs, \"\\n\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not extract review count from span.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f74a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now scraping *all* pages for: https://www.glassdoor.com/Reviews/Daffodil-International-University-Reviews-E1394524.htm\n",
      "Total reviews = 102, Pages = 11\n",
      "Saving reviews in: Daffodil-International-University-Reviews-E1394524.txt\n",
      "\n",
      "-----\n",
      "\n",
      "Now scraping *all* pages for: https://www.glassdoor.com/Reviews/International-Islamic-University-Chittagong-Reviews-E936727.htm\n",
      "Total reviews = 25, Pages = 3\n",
      "Saving reviews in: International-Islamic-University-Chittagong-Reviews-E936727.txt\n",
      "\n",
      "-----\n",
      "\n",
      "Now scraping *all* pages for: https://www.glassdoor.com/Reviews/East-Delta-University-Reviews-E2352449.htm\n",
      "Total reviews = 11, Pages = 2\n",
      "Saving reviews in: East-Delta-University-Reviews-E2352449.txt\n",
      "\n",
      "-----\n",
      "\n",
      "Now scraping *all* pages for: https://www.glassdoor.com/Reviews/North-South-University-Reviews-E465930.htm\n",
      "Total reviews = 199, Pages = 20\n",
      "Saving reviews in: North-South-University-Reviews-E465930.txt\n",
      "\n",
      "-----\n",
      "\n",
      "Now scraping *all* pages for: https://www.glassdoor.com/Reviews/East-West-University-Reviews-E128305.htm\n",
      "Total reviews = 45, Pages = 5\n",
      "Saving reviews in: East-West-University-Reviews-E128305.txt\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# We'll now loop through 'pages_info' to scrape each URL's paginated links\n",
    "# and save the reviews to separate .txt files (one per link).\n",
    "for g_url, (total_reviews, total_tabs) in pages_info.items():\n",
    "    # Create a descriptive filename, based on the last part of the URL\n",
    "    # Example: \"Daffodil-International-University-Reviews-E1394524.htm\" -> \"Daffodil-International-University-Reviews-E1394524.txt\"\n",
    "    base_name = os.path.splitext(os.path.basename(g_url))[0]  # remove \".htm\"\n",
    "    file_name = f\"{base_name}.txt\"\n",
    "\n",
    "    print(f\"Now scraping *all* pages for: {g_url}\")\n",
    "    print(f\"Total reviews = {total_reviews}, Pages = {total_tabs}\")\n",
    "    print(f\"Saving reviews in: {file_name}\\n\")\n",
    "\n",
    "    # 1) Strip '.htm' to prepare for \"_P{page}.htm\"\n",
    "    url_base = g_url.replace(\".htm\", \"\")\n",
    "\n",
    "    # 2) Generate list of paginated URLs\n",
    "    urls = [\n",
    "        f\"{url_base}{'_P' + str(page) if page > 1 else ''}.htm\"\n",
    "        for page in range(1, total_tabs + 1)\n",
    "    ]\n",
    "\n",
    "    # 3) Perform batch scrape\n",
    "    result = app.batch_scrape_urls(\n",
    "        urls=urls,\n",
    "        params={\"formats\": [\"html\"]}\n",
    "    )\n",
    "\n",
    "    # 4) Open the file (write mode) to store all pages' reviews for this link\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        # 5) Extract and write the review sections from each page\n",
    "        for index, data in enumerate(result.get('data', []), start=1):\n",
    "            html = data.get('html', '')\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            reviews_section = soup.find('div', id='ReviewsFeed', attrs={'data-test': 'reviews-list'})\n",
    "            if reviews_section:\n",
    "                # Write the raw text of the reviews section to the file.\n",
    "                # (You could refine this to extract each review separately.)\n",
    "                f.write(f\"\\n--- Page {index} of {g_url} ---\\n\")\n",
    "                f.write(reviews_section.get_text(separator=\"\\n\", strip=True))\n",
    "            # No need to show the output in console.\n",
    "            # We're simply writing everything to the .txt file.\n",
    "\n",
    "    print(\"-----\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
